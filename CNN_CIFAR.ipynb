{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p84eMWjuIXsW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vztp2WSpR59_",
        "outputId": "0bbf3158-a8ae-477a-e039-602e4ec1f85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "# tfs = T.Compose( [T.Resize((28, 28)), T.Grayscale(num_output_channels = 3), T.ToTensor()] ) # MNIST\n",
        "tfs = T.Compose( [T.Resize((32, 32)), T.ToTensor()] )\n",
        "\n",
        "ds = CIFAR10(root = \"datasets\", train = True, download = True, transform = tfs)\n",
        "ts_ds = CIFAR10(root = \"datasets\", train = False, download = True, transform = tfs)\n",
        "classes = ds.classes\n",
        "print(classes)\n",
        "n_cls = len(classes)\n",
        "n_cls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hWKatuPZM-u",
        "outputId": "12a8469d-42f3-44d1-a002-489c95a1e4c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(45000, 5000)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "total_len = len(ds)\n",
        "tr_len = int(total_len * 0.9)\n",
        "vl_len = total_len - tr_len\n",
        "tr_len, vl_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz5EinzpLK2I",
        "outputId": "5d552c2f-e1b4-459d-cac4-682d7d0f81f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45000 5000\n"
          ]
        }
      ],
      "source": [
        "tr_ds, vl_ds = random_split(dataset = ds, lengths=[tr_len, vl_len])\n",
        "print(len(tr_ds),len(vl_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5XZodzJZUlS",
        "outputId": "cb4c1dcf-e0b6-43a6-c69d-0db5398c266e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "bs = 128\n",
        "tr_dl = DataLoader(dataset = tr_ds, batch_size = bs, shuffle = True, num_workers = 8)\n",
        "vl_dl = DataLoader(dataset = vl_ds, batch_size = bs, shuffle = False, num_workers = 8)\n",
        "ts_dl = DataLoader(dataset = ts_ds, batch_size = 1,  shuffle = False, num_workers = 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGkawoglMUx4"
      },
      "source": [
        "## AI Model with Linear Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBy_yiQ-nOGk",
        "outputId": "749c7421-3398-4085-9bca-dbb6dafd0194"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 16, 16])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = torch.rand(1, 3, 32, 32) # 4D -> (bs, im_chs, im_h, im_w)\n",
        "# 2 ni darajalari; 8 -> 16 -> 32\n",
        "# stride -> filterning qadami\n",
        "# conv = Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 1, stride = 1) # Linear in_features, out_features; out_channels == filter soniga == kernellar soniga\n",
        "# formula: [(32 + 2 * 1 - 3) / 1] + 1 = 32\n",
        "# conv = Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 0, stride = 1) # Linear in_features, out_features; out_channels == filter soniga == kernellar soniga\n",
        "# formula: [(32 + 0 - 3) / 1] + 1 = 29 + 1 = 30\n",
        "conv = Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 1, stride = 2) # Linear in_features, out_features; out_channels == filter soniga == kernellar soniga\n",
        "# formula: [(32 + 2 - 3) / 2] + 1 = 15 + 1 = 16\n",
        "mp = MaxPool2d(kernel_size = 2, stride = 2) # backpropda qatnashmaydi: trainable parametrlari yo'q\n",
        "mp(inp).shape\n",
        "\n",
        "# conv(inp).shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05FbOT4-UrbZ",
        "outputId": "169f7988-e559-4b2d-ce58-b8629d9ac257"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn import *\n",
        "\n",
        "class CustomModel(Module):\n",
        "\n",
        "  def __init__(self, in_chs, out_chs, ks, p, s, in_fs, out_fs, n_cls):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_1 = Conv2d(in_channels = in_chs, out_channels = out_chs, kernel_size = ks, padding = p, stride = s)\n",
        "    self.conv_2 = Conv2d(in_channels = out_chs, out_channels = out_chs * 2, kernel_size = ks, padding = p, stride = s)\n",
        "    # self.conv_3 = Conv2d(in_channels = out_chs, out_channels = out_chs * 2, kernel_size = ks, padding = p, stride = s)\n",
        "\n",
        "    self.lin_layer = Linear(in_features = in_fs, out_features = out_fs)\n",
        "    self.classifier = Linear(in_features = out_fs, out_features = n_cls)\n",
        "    self.act = ReLU() # prelu, leaky relu, elu,...\n",
        "    self.mp = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "  def forward(self, inp):\n",
        "\n",
        "    out = self.conv_1(inp)        # (bs, out_chs, im_h, im_w)\n",
        "    out = self.mp(self.act(out))  # (bs, out_chs, im_h // 2, im_w // 2)\n",
        "    out = self.conv_2(out)        # (bs, out_chs * 2, im_h // 2, im_w // 2)\n",
        "    out = self.mp(self.act(out))  # (bs, out_chs * 2, im_h // 4, im_w // 4)\n",
        "\n",
        "    bs = inp.shape[0]\n",
        "    out = out.view(bs, -1)\n",
        "\n",
        "    out = self.lin_layer(out)\n",
        "    out = self.act(out)\n",
        "    out = self.classifier(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "inp = torch.rand(1,3,32,32)\n",
        "out_fs = 256\n",
        "m = CustomModel(in_chs = inp.shape[1], out_chs = 8, ks = 3, p = 1, s = 1, in_fs = 1024, out_fs = out_fs, n_cls = n_cls)\n",
        "xom_bashorat = m(inp)\n",
        "xom_bashorat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuuRSuaGy3vY",
        "outputId": "d131c81e-b983-4513-8c41-e7ee3916bfc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "266362"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model = m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfsqdAn_NeFb",
        "outputId": "2388257b-d6ed-4e62-f82e-ad7157af3d51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-epochdagi train loss -> 1.922\n",
            "1-epochdagi train acc  -> 0.313\n",
            "1-epochdagi validation loss -> 1.688\n",
            "1-epochdagi validation acc -> 0.399\n",
            "2-epochdagi train loss -> 1.627\n",
            "2-epochdagi train acc  -> 0.418\n",
            "2-epochdagi validation loss -> 1.593\n",
            "2-epochdagi validation acc -> 0.423\n",
            "3-epochdagi train loss -> 1.528\n",
            "3-epochdagi train acc  -> 0.453\n",
            "3-epochdagi validation loss -> 1.490\n",
            "3-epochdagi validation acc -> 0.468\n",
            "4-epochdagi train loss -> 1.458\n",
            "4-epochdagi train acc  -> 0.479\n",
            "4-epochdagi validation loss -> 1.429\n",
            "4-epochdagi validation acc -> 0.488\n",
            "5-epochdagi train loss -> 1.396\n",
            "5-epochdagi train acc  -> 0.504\n",
            "5-epochdagi validation loss -> 1.371\n",
            "5-epochdagi validation acc -> 0.505\n",
            "6-epochdagi train loss -> 1.350\n",
            "6-epochdagi train acc  -> 0.519\n",
            "6-epochdagi validation loss -> 1.330\n",
            "6-epochdagi validation acc -> 0.524\n",
            "7-epochdagi train loss -> 1.301\n",
            "7-epochdagi train acc  -> 0.541\n",
            "7-epochdagi validation loss -> 1.321\n",
            "7-epochdagi validation acc -> 0.526\n",
            "8-epochdagi train loss -> 1.266\n",
            "8-epochdagi train acc  -> 0.551\n",
            "8-epochdagi validation loss -> 1.271\n",
            "8-epochdagi validation acc -> 0.546\n",
            "9-epochdagi train loss -> 1.235\n",
            "9-epochdagi train acc  -> 0.564\n",
            "9-epochdagi validation loss -> 1.244\n",
            "9-epochdagi validation acc -> 0.568\n",
            "10-epochdagi train loss -> 1.200\n",
            "10-epochdagi train acc  -> 0.575\n",
            "10-epochdagi validation loss -> 1.211\n",
            "10-epochdagi validation acc -> 0.578\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr = 3e-4)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  # if epoch == 1: break\n",
        "  tr_epoch_acc = 0\n",
        "  tr_epoch_loss = 0\n",
        "  vl_epoch_acc = 0\n",
        "  vl_epoch_loss = 0\n",
        "\n",
        "  for idx, batch in enumerate(tr_dl):\n",
        "\n",
        "    rasmlar, javoblar = batch\n",
        "\n",
        "    xom_bashoratlar = m(rasmlar)\n",
        "    bashoratlar = torch.argmax(xom_bashoratlar, dim = 1)\n",
        "\n",
        "    loss = loss_fn(xom_bashoratlar, javoblar) #\n",
        "    tr_epoch_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch_acc = (bashoratlar == javoblar).sum().item()\n",
        "    tr_epoch_acc += batch_acc\n",
        "\n",
        "  print(f\"{epoch + 1}-epochdagi train loss -> {tr_epoch_loss / len(tr_dl):.3f}\")\n",
        "  print(f\"{epoch + 1}-epochdagi train acc  -> {tr_epoch_acc / len(tr_dl.dataset):.3f}\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, batch in enumerate(vl_dl):\n",
        "      rasmlar, javoblar = batch\n",
        "      xom_bashoratlar = m(rasmlar)\n",
        "      bashoratlar = torch.argmax(xom_bashoratlar, dim = 1)\n",
        "      loss = loss_fn(xom_bashoratlar, javoblar)\n",
        "      vl_epoch_loss += loss.item()\n",
        "\n",
        "      batch_acc = (bashoratlar == javoblar).sum().item()\n",
        "      vl_epoch_acc += batch_acc\n",
        "\n",
        "  print(f\"{epoch + 1}-epochdagi validation loss -> {vl_epoch_loss / len(vl_dl):.3f}\")\n",
        "  print(f\"{epoch + 1}-epochdagi validation acc -> {vl_epoch_acc / len(vl_dl.dataset):.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
